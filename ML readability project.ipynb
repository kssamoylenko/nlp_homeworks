{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание ридабилити научно-популярных текстов при помощи машинного обучения "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Под ридабилити традицонно понимается \"удобочитаемость\" текстов, то есть их понятность и легкость чтения. Чаще всего для этого используются различные метрики, основанные на статистических подсчетах средней длины предложений, слов в них, количества \"сложных слов\" и т.д., и различные соотношения между этими характеристиками.\n",
    "\n",
    "Оценка ридабилити научно-популярных текстов -- одна из задач в рамках нашего НИСа. Я решила попробовать решить ее при помощи машинного обучения.\n",
    "Наш корпус составляет около 30 тыс. текстов, выкаченных с различных ресурсов. \n",
    "\n",
    "Я взяла **320**  из них (для обучения это, конечно, немного) и разбила на **три класса** по уровню сложности: простые (содержание понятно и можно легко пересказать, не содержит специфических терминов и не требует глубокого знания контекста), средние (рассказывают о какой-то идее или концепции, для понимания нужно знать ряд терминов и/или контекст), сложные (серьезное научное изложение, для понимания необходимо знать контекст, понять о чем речь в полной мере не представляется возможным без спец образования или отдельного изучения предмета).\n",
    "\n",
    "Я написала [модуль](https://github.com/ana-kuznetsova/Popular-Science-Texts-Compling-research/blob/master/readability/readability_metrics.py) на питоне, который позволяет посчитать следующие метрики:\n",
    "* *Flesch reading ease (FRE)* -- индекс удобочитаемости Флеша. Считает соотношение общего количество слов, предложений и количества слогов. Чем меньше значение, тем сложнее текст (отсчет идет от 100 и иногда может уходить в минус)\n",
    "\n",
    "* *Flesh-Kincaid Grade (FKG)* -- считает индекс Флеша и переводит его в шкалу от 0 до 20 (с возможным превышением), ставя в соответствие необходимый уровень образования (5 -- 5 класс, 12 -- выпускник школы, от 14 и выше -- студенты и специалисты, и т.д.). Такой перевод используется и в остальных метриках. \n",
    "\n",
    "* *SMOG index* --  считает количество слов, в которых более 3 слогов и их количество в предложениях\n",
    "\n",
    "* *Coleman-Liau index (CLI )* -- считает не количество слогов, а количество букв в словах и слов в предложениях\n",
    "\n",
    "* *Dale chall readability score (DCH)* -- количество сложных слов и средняя длина предложений\n",
    "\n",
    "* *Gunning fog* -- считает сложные слова (более 3 слогов) и их количество в тексте\n",
    "\n",
    "В работе с этими метриками пришлось учитывать две особенности: во-первых, они разработаны для английского языка, поэтому для русского пришлось подбирать адаптации (считать \"сложными\" слова, в которых более 4 слогов, а не 3, изучить альтернативные коэффиценты для каждой формулы), а во-вторых, научно-популярные тексты не ориентированы на школьников, а чаще всего предназначены для образованных людей, поэтому такие статистические метрики почти всегда будут присваивать им высокий уровень сложности.\n",
    "\n",
    "Несмотря на эти ограничения, я постаралась попробовать предсказать уровень сложности текстов на основе этих метрик.\n",
    "\n",
    "На вход подается набор текстов, у каждого из которого есть метка класса -- 1, 2, или 3.\n",
    "\n",
    "**Признаками** для машинного обучения стали векторы, полученные благодаря подсчетам описанных выше метрик для каждого текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = pd.read_csv('scipop5.csv', encoding = 'utf-8') \n",
    "texts = texts.drop(['Unnamed: 0'], axis=1)\n",
    "train, test = train_test_split(texts, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train['class'] \n",
    "y_test = test['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Агентство НАСА и Роскосмос, обсудив все нюансы...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>У проблемы ГМО много аспектов. Есть медицински...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Как выглядят миноги. Фрагмен...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>История нужна, чтобы упорядочить мир. Поток бо...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>В конце января команда охотников з...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Астрофотографы Гевин Хэффернан и Харун Мехмеди...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Как сделать материал толщиной в атом, благодар...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>«Сколько-сколько рукопожатий?» Все ли мы знаем...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>Группа исследователей из трех различных лабора...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Мы публикуем полную стенограмму лекции директо...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  class\n",
       "34   Агентство НАСА и Роскосмос, обсудив все нюансы...      1\n",
       "71   У проблемы ГМО много аспектов. Есть медицински...      1\n",
       "107                    Как выглядят миноги. Фрагмен...      1\n",
       "184  История нужна, чтобы упорядочить мир. Поток бо...      2\n",
       "230              В конце января команда охотников з...      2\n",
       "52   Астрофотографы Гевин Хэффернан и Харун Мехмеди...      1\n",
       "168  Как сделать материал толщиной в атом, благодар...      2\n",
       "38   «Сколько-сколько рукопожатий?» Все ли мы знаем...      1\n",
       "272  Группа исследователей из трех различных лабора...      3\n",
       "211  Мы публикуем полную стенограмму лекции директо...      2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ksslib.readability_metrics as kk #импорт модуля с метриками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def statist_vectors(text):\n",
    "    FRE = kk.flesch_RE(text)\n",
    "    FKG = kk.flesch_kincaid_grade(text)\n",
    "    SMOG = kk.smog_index(text)\n",
    "    CLI = kk.coleman_liau_index(text)\n",
    "    DCH = kk.dale_chall_score(text)\n",
    "    GF = kk.gunning_fog(text)\n",
    "    return [FRE, FKG, SMOG, CLI, DCH, GF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_me_all(texts):\n",
    "    return [statist_vectors(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train = count_me_all(train['text']) #считаем признаки для тестовой и обучающей выборки\n",
    "x_test = count_me_all(test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[39.43, 12.6, 13.0, 19.25, 7.65, 15.9],\n",
       " [46.01, 11.5, 12.9, 17.97, 7.63, 15.8],\n",
       " [12.02, 17.7, 15.4, 19.26, 8.57, 19.3],\n",
       " [23.53, 17.5, 16.9, 21.12, 8.93, 21.2],\n",
       " [24.75, 15.5, 14.8, 18.27, 8.34, 18.4],\n",
       " [40.24, 13.9, 14.8, 18.16, 8.15, 18.3],\n",
       " [13.09, 19.9, 18.3, 23.04, 9.46, 23.3],\n",
       " [47.52, 12.4, 12.8, 16.59, 7.24, 15.6],\n",
       " [12.39, 21.6, 18.9, 20.84, 9.38, 24.4],\n",
       " [44.66, 12.6, 13.3, 16.7, 7.55, 16.3]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler #нормируем наши вектора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_fit = scaler.fit(x_train)\n",
    "x_transform = scaler.transform(x_train)\n",
    "x_fit_test = scaler.fit(x_test)\n",
    "x_transform_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.78807593, -0.91055367, -0.99793199, -0.3778168 , -0.90105464,\n",
       "        -1.00313927],\n",
       "       [ 1.20042634, -1.20775507, -1.04014117, -0.74648468, -0.92195661,\n",
       "        -1.03200941],\n",
       "       [-0.929633  ,  0.46738006,  0.01508835, -0.37493658,  0.06043602,\n",
       "        -0.02155463],\n",
       "       [-0.20833311,  0.41334344,  0.64822606,  0.16078392,  0.43667149,\n",
       "         0.52697797],\n",
       "       [-0.13187909, -0.12702273, -0.23816674, -0.66007814, -0.17993665,\n",
       "        -0.28138586],\n",
       "       [ 0.83883639, -0.55931566, -0.23816674, -0.69176054, -0.37850537,\n",
       "        -0.31025599],\n",
       "       [-0.86257905,  1.06178285,  1.2391546 ,  0.71378573,  0.99057372,\n",
       "         1.13325084],\n",
       "       [ 1.29505387, -0.96459029, -1.08235035, -1.14395473, -1.32954504,\n",
       "        -1.08974968],\n",
       "       [-0.90644612,  1.52109409,  1.49240968,  0.08013782,  0.90696583,\n",
       "         1.45082234],\n",
       "       [ 1.11582558, -0.91055367, -0.87130445, -1.11227233, -1.0055645 ,\n",
       "        -0.88765873]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_transform [:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для решения данной задачи я решила опробовать мектор опорных векторов и метод k-ближайших соседей. Смотрим, что получается"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.60      0.61        40\n",
      "          2       0.42      0.63      0.51        35\n",
      "          3       0.20      0.05      0.08        21\n",
      "\n",
      "avg / total       0.45      0.49      0.45        96\n",
      "\n",
      "[[24 15  1]\n",
      " [10 22  3]\n",
      " [ 5 15  1]]\n"
     ]
    }
   ],
   "source": [
    "model_svc = SVC()\n",
    "model_svc.fit(x_transform, y_train)\n",
    "\n",
    "expected_svc = y_test\n",
    "predicted_svc = model_svc.predict(x_transform_test)\n",
    "\n",
    "print(metrics.classification_report(expected_svc, predicted_svc))\n",
    "print(metrics.confusion_matrix(expected_svc, predicted_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.68      0.57        40\n",
      "          2       0.47      0.49      0.48        35\n",
      "          3       0.20      0.05      0.08        21\n",
      "\n",
      "avg / total       0.42      0.47      0.43        96\n",
      "\n",
      "[[27  9  4]\n",
      " [18 17  0]\n",
      " [10 10  1]]\n"
     ]
    }
   ],
   "source": [
    "model_kn = KNeighborsClassifier()\n",
    "model_kn.fit(x_transform, y_train)\n",
    "\n",
    "expected = y_test\n",
    "predicted = model_kn.predict(x_transform_test)\n",
    "\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты выглядят не очень впечатляющими. Метод опорных векторов в целом справилс чуть лучше, примечательно, что с чуть большей точностью, чем все остальное, определяются тексты первого класса, и очень плохо -- третьего.\n",
    "\n",
    "В целом было бы ошибочно надеяться, что статистические метрики определяют сложность текстапо такому же принципу, что и человек. Возможным решением было бы создание дополнительных признаков: подсчет количества терминов, абстрактных и разговорных выражений, а также тональность текста (здесь можно предположить, что чем эмоциональнее что-либо объясняется, тем более доступным оно кажется читателю). \n",
    "\n",
    "В целом данное решение (точнее, зайдествованный для него модуль) полезно для оценки именно статистических характеристик для русского языка, т.к. в него вошли самые актуальные коэффициенты и наработки по этой теме. В то же время этот результат показывает, что машинное обучение только на количественных признаках неэффективно и статистические параметры не отражают человеческого представления о сложности текста, и, по всей видимости, для более точного результата модель обучения необходимо усложнить."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
